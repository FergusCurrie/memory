{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in flashcards_to_migrate.db:\n",
      "notes\n",
      "sqlite_sequence\n",
      "reviews\n",
      "cards\n",
      "code_completion\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('flashcards_to_migrate.db')\n",
    "\n",
    "# Query to get all table names\n",
    "table_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "\n",
    "# Execute the query and fetch all results\n",
    "tables = pd.read_sql_query(table_query, conn)\n",
    "\n",
    "# Print all table names\n",
    "print(\"Tables in flashcards_to_migrate.db:\")\n",
    "for table in tables['name']:\n",
    "    print(table)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows in code_completion table:\n",
      "    id  note_id                                               code  \\\n",
      "0    2        2  from polars import selectors as cs\\nresult = (...   \n",
      "1    3        3  result = (\\n    contoso_sales\\n    .group_by('...   \n",
      "2    4        4  result = (\\n    contoso_sales\\n    .group_by('...   \n",
      "3    5        5  result = contoso_sales.select(\\n    'Category'...   \n",
      "4    6        6  result = temperatures.select('avg_temp_celsius...   \n",
      "5    7        7                 result = temperatures.drop_nulls()   \n",
      "6    8        8  cols_to_drop = [\\n    column \\n    for column ...   \n",
      "7    9        9  result = temperatures.select(\\n    pl.col('avg...   \n",
      "8   10       10  result = temperatures.select(\\n    pl.col('avg...   \n",
      "9   11       11  result = temperatures.select(\\n    pl.col('avg...   \n",
      "10  12       12  result = (\\n    google_store_reviews\\n    .fil...   \n",
      "11  13       13  result = (\\n    google_store_reviews\\n    .fil...   \n",
      "12  14       14  result = (\\n    google_store_reviews\\n    .fil...   \n",
      "13  15       15  result = academic.unpivot(\\n    index='year',\\...   \n",
      "14  16       16  result = (\\n    pokemon\\n    .select('HP','Def...   \n",
      "15  17       17  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "16  19       19  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "17  20       20  result = (\\n    preprocessed\\n    .group_by('t...   \n",
      "18  21       21  \\nresult = (\\n    preprocessed\\n    .select(\\n...   \n",
      "19  22       22  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "20  23       23  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "21  24       24  result = (\\n    preprocessed\\n    .with_column...   \n",
      "22  25       25  result = (\\n    preprocessed\\n    .with_column...   \n",
      "23  26       26  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "24  27       27  result = (\\n    preprocessed\\n    .with_column...   \n",
      "25  28       28  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "26  29       29  result = (\\n    preprocessed\\n    .explode('li...   \n",
      "27  30       30  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "28  31       31  result = (\\n    preprocessed\\n    .pivot(\\n   ...   \n",
      "\n",
      "                                  problem_description  \\\n",
      "0                            Sum the numeric columns    \n",
      "1   Summarise the brand column as sum of the quant...   \n",
      "2   Aggregate brand column by taking the first cus...   \n",
      "3   Return the category and Subcategory columns an...   \n",
      "4   Get the count of nulls in avgerage temperature...   \n",
      "5                Drop all null values from dataframe    \n",
      "6                  Drop any column with a null value    \n",
      "7   Create a new column avg_temp_nulls_filled, wit...   \n",
      "8   Select the column avg_temp_celsius and a new c...   \n",
      "9   Select the column avg_temp_celsius and a new c...   \n",
      "10  Filter to rows where content begins with 'Very...   \n",
      "11  Filter this to rows where 'content' has the st...   \n",
      "12  Filter to rows where 'content' has one of thes...   \n",
      "13  Convert wide into long by moving ['students','...   \n",
      "14             Sum the rows of columns HP and Defense   \n",
      "15  Create column sales amount as window function ...   \n",
      "16  Select tags and a new column, 'tags in list' w...   \n",
      "17  Return two columns. The first is date, the sec...   \n",
      "18  Return a dataframe with 1 column. It should be...   \n",
      "19  There's a preprocessed dataframe with list of ...   \n",
      "20  There's a preprocessed dataframe with list of ...   \n",
      "21  There's a preprocessed dataframe with list of ...   \n",
      "22  There's a preprocessed dataframe with list of ...   \n",
      "23  There's a preprocessed dataframe with list of ...   \n",
      "24  There's a preprocessed dataframe with two colu...   \n",
      "25  There's a preprocessed dataframe with lists of...   \n",
      "26  There's a preprocessed dataframe with lists of...   \n",
      "27  There's a preprocessed dataframe with lists of...   \n",
      "28  There's a preprocessed dataset with some casti...   \n",
      "\n",
      "                dataset_name  \\\n",
      "0          contoso_sales.csv   \n",
      "1          contoso_sales.csv   \n",
      "2          contoso_sales.csv   \n",
      "3          contoso_sales.csv   \n",
      "4           temperatures.csv   \n",
      "5           temperatures.csv   \n",
      "6           temperatures.csv   \n",
      "7           temperatures.csv   \n",
      "8           temperatures.csv   \n",
      "9           temperatures.csv   \n",
      "10  google_store_reviews.csv   \n",
      "11  google_store_reviews.csv   \n",
      "12  google_store_reviews.csv   \n",
      "13              academic.csv   \n",
      "14               pokemon.csv   \n",
      "15         contoso_sales.csv   \n",
      "16             us_videos.csv   \n",
      "17             us_videos.csv   \n",
      "18             us_videos.csv   \n",
      "19             us_videos.csv   \n",
      "20             us_videos.csv   \n",
      "21             us_videos.csv   \n",
      "22             us_videos.csv   \n",
      "23             us_videos.csv   \n",
      "24             us_videos.csv   \n",
      "25             us_videos.csv   \n",
      "26             us_videos.csv   \n",
      "27             us_videos.csv   \n",
      "28              academic.csv   \n",
      "\n",
      "                                   preprocessing_code  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "5                                                       \n",
      "6                                                       \n",
      "7                                                       \n",
      "8                                                       \n",
      "9                                                       \n",
      "10                                                      \n",
      "11                                                      \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                                                      \n",
      "15  preprocessed = contoso_sales.with_columns(\\n  ...   \n",
      "16  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "17  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "18  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "19  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "20  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "21  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "22  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "23  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "24  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "25  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "26  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "27  preprocessed = (\\n    us_videos\\n    .with_col...   \n",
      "28  \\n\\nfrom polars import selectors as cs\\nprepro...   \n",
      "\n",
      "                                           code_start  \\\n",
      "0                                                None   \n",
      "1                                                None   \n",
      "2                                                None   \n",
      "3                                                None   \n",
      "4                                                None   \n",
      "5                                                None   \n",
      "6                                                None   \n",
      "7                                                None   \n",
      "8                                                None   \n",
      "9                                                None   \n",
      "10                                               None   \n",
      "11                                               None   \n",
      "12                                               None   \n",
      "13                                               None   \n",
      "14                       result = (\\n    pokemon\\n)\\n   \n",
      "15                    result = (\\n    preprocessed\\n)   \n",
      "16  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "17              result = (\\n    preprocessed\\n    \\n)   \n",
      "18              result = (\\n    preprocessed\\n    \\n)   \n",
      "19  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "20  result = (\\n    preprocessed\\n    .select(\\n  ...   \n",
      "21  result = (\\n    preprocessed\\n    .with_column...   \n",
      "22  result = (\\n    preprocessed\\n    .with_column...   \n",
      "23  result = (\\n    preprocessed\\n    .with_column...   \n",
      "24  result = (\\n    preprocessed\\n    .with_column...   \n",
      "25  result = (\\n    preprocessed\\n    .with_column...   \n",
      "26  result = (\\n    preprocessed\\n    .with_column...   \n",
      "27  result = (\\n    preprocessed\\n    .with_column...   \n",
      "28                    result = (\\n    preprocessed\\n)   \n",
      "\n",
      "                                      dataset_headers  \n",
      "0   {\"contoso_sales\": \"{\\\"Order Number\\\":{\\\"0\\\":28...  \n",
      "1   {\"contoso_sales\": \"{\\\"Order Number\\\":{\\\"0\\\":28...  \n",
      "2   {\"contoso_sales\": \"{\\\"Order Number\\\":{\\\"0\\\":28...  \n",
      "3   {\"contoso_sales\": \"{\\\"Order Number\\\":{\\\"0\\\":28...  \n",
      "4   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "5   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "6   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "7   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "8   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "9   {\"temperatures\": \"{\\\"date\\\":{\\\"0\\\":\\\"2023-01-0...  \n",
      "10  {\"google_store_reviews\": \"{\\\"reviewId\\\":{\\\"0\\\"...  \n",
      "11  {\"google_store_reviews\": \"{\\\"reviewId\\\":{\\\"0\\\"...  \n",
      "12  {\"google_store_reviews\": \"{\\\"reviewId\\\":{\\\"0\\\"...  \n",
      "13  {\"academic\": \"{\\\"year\\\":{\\\"0\\\":\\\"1948\\\\/49\\\",\\...  \n",
      "14  {\"pokemon\": \"{\\\"#\\\":{\\\"0\\\":1,\\\"1\\\":2,\\\"2\\\":3},...  \n",
      "15  {\"contoso_sales\": \"{\\\"Order Number\\\":{\\\"0\\\":28...  \n",
      "16  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "17  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "18  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "19  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "20  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "21  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "22  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "23  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "24  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "25  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "26  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "27  {\"us_videos\": \"{\\\"video_id\\\":{\\\"0\\\":\\\"2kyS6SvS...  \n",
      "28  {\"academic\": \"{\\\"year\\\":{\\\"0\\\":\\\"1948\\\\/49\\\",\\...  \n"
     ]
    }
   ],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('flashcards_to_migrate.db')\n",
    "\n",
    "# Query to get all rows from the code_completition table\n",
    "query = \"SELECT * FROM code_completion;\"\n",
    "\n",
    "# Execute the query and fetch all results into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display all rows from the code_completition table\n",
    "print(\"All rows in code_completion table:\")\n",
    "print(df)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in code_completion table:\n",
      "Index(['id', 'note_id', 'code', 'problem_description', 'dataset_name',\n",
      "       'preprocessing_code', 'code_start', 'dataset_headers'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('flashcards_to_migrate.db')\n",
    "\n",
    "# Query to get all rows from the code_completion table\n",
    "query = \"SELECT * FROM code_completion;\"\n",
    "\n",
    "# Execute the query and fetch all results into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Print column names of code_completion table\n",
    "print(\"Column names in code_completion table:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added problem 1\n",
      "Successfully added problem 2\n",
      "Successfully added problem 3\n",
      "Successfully added problem 4\n",
      "Successfully added problem 5\n",
      "Successfully added problem 6\n",
      "Successfully added problem 7\n",
      "Successfully added problem 8\n",
      "Successfully added problem 9\n",
      "Successfully added problem 10\n",
      "Successfully added problem 11\n",
      "Successfully added problem 12\n",
      "Successfully added problem 13\n",
      "Successfully added problem 14\n",
      "Successfully added problem 15\n",
      "Successfully added problem 16\n",
      "Successfully added problem 17\n",
      "Successfully added problem 18\n",
      "Successfully added problem 19\n",
      "Successfully added problem 20\n",
      "Successfully added problem 21\n",
      "Successfully added problem 22\n",
      "Successfully added problem 23\n",
      "Successfully added problem 24\n",
      "Successfully added problem 25\n",
      "Successfully added problem 26\n",
      "Successfully added problem 27\n",
      "Successfully added problem 28\n",
      "Successfully added problem 29\n",
      "Migration completed.\n"
     ]
    }
   ],
   "source": [
    "from backend.db.problem_model import add_new_polars_problem\n",
    "\n",
    "# add_new_polars_problem(code, problem_description, datasets, preprocessing_code, code_start, type):\n",
    "\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the necessary information from the row\n",
    "    code = row['code']\n",
    "    problem_description = row['problem_description']\n",
    "    datasets = row['dataset_name'].split(',')  # Assuming dataset names are comma-separated\n",
    "    preprocessing_code = row['preprocessing_code']\n",
    "    code_start = row['code_start']\n",
    "    problem_type = 'polars' # row['type']\n",
    "\n",
    "    # Call the function to add the problem to the new database\n",
    "    try:\n",
    "        add_new_polars_problem(code, problem_description, datasets, preprocessing_code, code_start, problem_type)\n",
    "        print(f\"Successfully added problem {index + 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding problem {index + 1}: {str(e)}\")\n",
    "\n",
    "print(\"Migration completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memory-7yvjw6ke-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
