2024-10-07 03:19:46,788 - backend.app - INFO - code='\nfrom pyspark.sql.functions import sum\n\nresult = academic.select(sum(academic["students"].cast("int")).alias("total_students"))\n\n' preprocessing_code='' dataset_names=['academic.csv'] problem_type='pyspark'
2024-10-07 03:19:46,789 - backend.code_execution.check_code - INFO - RUnning pyspark code
2024-10-07 03:19:46,811 - backend.code_execution.check_code - INFO - from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("LocalSparkExample").master("local[*]").getOrCreate()
academic = spark.createDataFrame(academic)

from pyspark.sql.functions import sum

result = academic.select(sum(academic["students"].cast("int")).alias("total_students"))


result = result.toPandas()
spark.stop()
2024-10-07 03:20:00,881 - backend.code_execution.check_code - INFO - (   total_students
0        29708383, None)
2024-10-07 03:20:11,402 - backend.db.problem_model - INFO - Inserted data for problem_id: 4
